{
  "hash": "6e1c8ad2fa3dabf10c48d38cd3dca6d1",
  "result": {
    "markdown": "# Multiple Regression\n\n<iframe src=\"https://teesside.hosted.panopto.com/Panopto/Pages/Embed.aspx?id=107176f8-2ebc-4f24-9bdc-adaa008f75a9&autoplay=false&offerviewer=true&showtitle=true&showbrand=false&captions=false&interactivity=all\" height=\"405\" width=\"100%\" style=\"border: 1px solid #464646;\" allowfullscreen allow=\"autoplay\"></iframe>\n\n\n## By the end of this session, you will be able to:\n\n\n\n\n\n- Compare multiple regression to simple regression\n- Describe the assumptions of multiple regression\n- Consider sample size in regression\n- Use categorical predictors in regression in R\n- Conduct different types of multiple regression\n- Interpret the output of Multiple regression\n\n## What is multiple regression?\n\n- An extension of simple regression\n- Same format as simple regression but adding each predictor: \n \n $$ Y = b_1X_1 + b_2X_2 + b_0 $$\n\n(The constant can be referred to in the equation as **c** or **b0** )\n\n## What are the assumptions of Multiple Regression?\n\n- They are primarily the same as simple regression\n- The additional assumption of no **multicollinearity** (due to having multiple predictors)\n  - i.e. predictors should not be highly correlated\n  \n## What is multicollinearity?\n\n- Multicollinearity = predictors correlated highly with each other.\n- This is not good because:\n  - It makes it difficult to determine the role of individual predictors\n  - Increases the error of the model (higher standard errors)\n  - Difficult to identify significant predictors - wider confidence interval\n\n## Testing multicollinearity  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## use the mctest package\n# install.packages(‘mctest’)o\nlibrary(mctest)\n\nm1 <- lm(aggression_level ~ treatment_group + treatment_duration + trust_score, data=regression_data)\n\nmctest(m1) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nomcdiag(mod = mod, Inter = TRUE, detr = detr, red = red, conf = conf, \n    theil = theil, cn = cn)\n\n\nOverall Multicollinearity Diagnostics\n\n                       MC Results detection\nDeterminant |X'X|:         0.9229         0\nFarrar Chi-Square:         7.7960         0\nRed Indicator:             0.1547         0\nSum of Lambda Inverse:     3.1728         0\nTheil's Method:           -0.8800         0\nCondition Number:         13.6549         0\n\n1 --> COLLINEARITY is detected by the test \n0 --> COLLINEARITY is not detected by the test\n```\n:::\n:::\n\n- The format of *mctest()* is: \n    \n    mctest(predictors, outcome)\n\n- In the above example we used the *cbind()* function to bind 3 columns of data together (the predictors) \n  \n  \n## Sample size for multiple regression\n\n- Is based on the number of predictors\n- More predictors = more participants needed\n- **Do a power analysis**\n- Loose \"rule of thumb\" = 10-15 participants per predictor\n\n\n\n## Approaches to multiple regression: All predictors at once\n\n> Research question: Do a client's treatment duration and treatment group predict aggression level?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel1 <- lm(data = regression_data, aggression_level ~ treatment_duration + treatment_group)\n```\n:::\n\n- Here we are including all of the predictors at the same time\n- Note that we are using a plus sign + between each predictor\n  - This means that no interactions will be tested\n\n### Using categorical predictors in R\n\n- Treatment group is a categorical (also called \"nominal\" or \"factor\") variable\n- No special \"dummy coding\" is required in R to use categorical predictors in regression\n- R will use the first group as the reference category and test whether being in another group shows a significant difference\n- R chooses the reference group based on numerical value or alphabetical order\n- If you want you can change the reference category or \"force\" it using the relevel function:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nregression_data$treatment_group <- relevel(regression_data$treatment_group, ref = \"therapy1\")\n```\n:::\n\n\n**More information in categorical predictors in section \\@ref(catreg) **\n\n### Reviewing the output\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = aggression_level ~ treatment_duration + treatment_group, \n    data = regression_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9468 -1.1104  0.0205  0.9621  3.4481 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)             11.58713    0.77331  14.984  < 2e-16 ***\ntreatment_duration      -0.66024    0.07119  -9.274 4.96e-15 ***\ntreatment_grouptherapy2  0.85032    0.30449   2.793   0.0063 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.5 on 97 degrees of freedom\nMultiple R-squared:  0.5206,\tAdjusted R-squared:  0.5107 \nF-statistic: 52.67 on 2 and 97 DF,  p-value: 3.267e-16\n```\n:::\n:::\n\n\n\n- Multiple R^2 = Total variance in outcome that is explained by the model\n- p-value = Statistical significance of the model\n- Coefficients = Contribution of each predictor to the model\n  - Pr = Significance of the individual predictor\n  - Estimate = Change in the outcome level that occurs when the predictor increases by 1 unit of measurement\n\n\n### All predictors at once (testing interactions)\n\n> Research questions: \n> - Do a client's treatment duration and treatment group  predict aggression level\n> - Do the predictors interact?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel2 <- lm(data = regression_data, aggression_level ~ treatment_duration * treatment_group)\n```\n:::\n\n- Here we are including all of the predictors at the same time\n- Note that we are using an asterisk * between each predictor\n  - This means that interactions will be tested\n\nReviewing the output\n\n<code style=\"font-size: 1em; width=100%;\">\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(model2) %>% coefficients\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                             Estimate Std. Error    t value\n(Intercept)                                12.3529190  1.1006127 11.2236751\ntreatment_duration                         -0.7334435  0.1033086 -7.0995381\ntreatment_grouptherapy2                    -0.5615517  1.4753596 -0.3806202\ntreatment_duration:treatment_grouptherapy2  0.1394649  0.1425977  0.9780305\n                                               Pr(>|t|)\n(Intercept)                                3.599000e-19\ntreatment_duration                         2.166226e-10\ntreatment_grouptherapy2                    7.043260e-01\ntreatment_duration:treatment_grouptherapy2 3.305175e-01\n```\n:::\n:::\n\n</code>\n\n\n- We get additional information in the coefficients table about the interaction between variables\n  - e.g. does the interaction between level of trust and treatment duration predict the outcome (aggression level)?\n\n- We can see from the output that none of the interactions are significant\n\n### Hierarchical multiple regression: Theory driven \"blocks\" of variables\n\n- It might be the case that we have previous research or theory to guide how we run the analysis\n- For example, we might know that treatment duration and therapy group are likely to predict the outcome\n- We might want to check whether client's level of trust in the clinician has any **additional** impact on our ability to predict the outcome (aggression level)\n\n> - To do this, we run three regression models\n>   - Model 0: the constant (baseline)\n>   - Model 1: treatment duration and therapy group\n>   - Model 2: treatment duration and therapy group and trust score\n\n- We then compare the two regression models to see if:\n  - Model 1 is better than Model 0 (the constant)\n  - Model 2 is better than Model 1\n\n**Hierarchical multiple regression: Running and comparing 2 models**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## run regression using the same method as above\nmodel0 <- lm(data = regression_data, aggression_level ~ 1)\nmodel1 <- lm(data = regression_data, aggression_level ~ treatment_duration + treatment_group)\nmodel2 <- lm(data = regression_data, aggression_level ~ treatment_duration + treatment_group + trust_score)\n\n## use the aov() command to compare the models\nanova(model0,model1,model2)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| Res.Df|      RSS| Df|   Sum of Sq|          F|   Pr(>F)|\n|------:|--------:|--:|-----------:|----------:|--------:|\n|     99| 455.2727| NA|          NA|         NA|       NA|\n|     97| 218.2601|  2| 237.0125863| 52.2194515| 0.000000|\n|     96| 217.8614|  1|   0.3986883|  0.1756808| 0.676048|\n\n</div>\n:::\n:::\n\n\n- We can see that:\n  - Model 1 (treatment duration and treatment group) is significant relative to the constant (Model 0)\n  - Model 2 (treatment duration, treatment group and trust score) shows no significant change compared to Model 1\n\n### Stepwise multiple regression: computational selection of predictors\n\n- Stepwise multiple regression is controversial because:\n  - The computer selects which predictors to include based on Akaike information criterion (AIC)\n    - This is a calculation of the quality of statistical models when they are compared to each other\n    \n  > ### What's the problem?\n  > - This selection is not based on any underlying theory or understanding of the real-life relationship between the variables \n\n### Stepwise multiple regression: loading the MASS package and run the full model\n\n1. **install and load the MASS package**\n1. **run a regression model with all of the variables**\n1. use the *stepAIC()* command on the full model to run stepwise regression\n1. View the best model\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(MASS)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'MASS' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'MASS'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:dplyr':\n\n    select\n```\n:::\n\n```{.r .cell-code}\n# Run the full model \nfull.model <- lm(data = regression_data, aggression_level ~ treatment_duration + treatment_group + trust_score)\n```\n:::\n\n\n### Stepwise multiple regression: Use stepAIC( ) with options\n\n- **Trace** *(TRUE or FALSE)*: do we want to see the steps that were involved in selecting the best model ?\n- **Direction** *(\"forward\", \"backward\" or \"both\")*: \n  - start with no variables and add them *(forward)*\n  - start with all variables and subtract them *(backward)*\n  - use both approaches *(both)*\n\n<code style=\"font-size: 1em; width=100%;\">\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Run stepwise\nstep.model <- stepAIC(full.model, direction = \"both\", trace = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStart:  AIC=85.87\naggression_level ~ treatment_duration + treatment_group + trust_score\n\n                     Df Sum of Sq    RSS     AIC\n- trust_score         1     0.399 218.26  84.052\n<none>                            217.86  85.869\n- treatment_group     1    17.877 235.74  91.755\n- treatment_duration  1   188.709 406.57 146.259\n\nStep:  AIC=84.05\naggression_level ~ treatment_duration + treatment_group\n\n                     Df Sum of Sq    RSS     AIC\n<none>                            218.26  84.052\n+ trust_score         1     0.399 217.86  85.869\n- treatment_group     1    17.547 235.81  89.785\n- treatment_duration  1   193.515 411.78 145.531\n```\n:::\n:::\n\n</code>\n\n### Stepwise multiple regression: Display the best model\n\n1. install and load the MASS package\n1. run a regression model with all of the variables\n1. **use the *stepAIC()* command on the full model to run stepwise regression** \n1. **View best model**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#view the stepwise output\nsummary(step.model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = aggression_level ~ treatment_duration + treatment_group, \n    data = regression_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9468 -1.1104  0.0205  0.9621  3.4481 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)             11.58713    0.77331  14.984  < 2e-16 ***\ntreatment_duration      -0.66024    0.07119  -9.274 4.96e-15 ***\ntreatment_grouptherapy2  0.85032    0.30449   2.793   0.0063 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.5 on 97 degrees of freedom\nMultiple R-squared:  0.5206,\tAdjusted R-squared:  0.5107 \nF-statistic: 52.67 on 2 and 97 DF,  p-value: 3.267e-16\n```\n:::\n:::\n\n\n## Using regression with categorical predictors (more information) {#catreg}\n\n**In the below video, you can click the icon in the top right of the video to change the layout (and remove my face, if you want!)**\n\n<iframe src=\"https://teesside.hosted.panopto.com/Panopto/Pages/Embed.aspx?id=01cdd2e6-c7dd-4677-a5b9-ae1b00caa8b7&autoplay=false&offerviewer=true&showtitle=true&showbrand=false&captions=false&interactivity=all\" height=\"405\" width=\"720\" style=\"border: 1px solid #464646;\" allowfullscreen allow=\"autoplay\"></iframe>\n\n\nPeople are often taught to use ANOVA to compare groups (i.e. if you have a categorical IV) and regression if you have continuous IVs. However, ANOVA and regression are the same thing, so it is possible to use regression to do analysis instead of ANOVA or ANCOVA. \n\nHowever, it might be difficult to understand how this is, so let's look at an example. The dataset **Baumann** compares 3 different methods of teaching reading comprehension. For this example, we will just look at the variable post.test.1 as the DV.\n\n\n### ANOVA Approach\n\nANOVA asks the question in the following way: \n\n> Is there a difference in reading comprehension scores between teaching groups?\n\nThe analysis takes the following approach:\n\n- What are the means of groups 1,2 and 3?\n- Are the means of groups 1,2 and 3 different?\n- Is the difference in means of groups 1,2 and 3 statistically significant?\n\nIf we were to summarise the data, we might present it in the following way:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n|group |     mean|       sd|\n|:-----|--------:|--------:|\n|Basal | 6.681818| 2.766920|\n|DRTA  | 9.772727| 2.724349|\n|Strat | 7.772727| 3.927095|\n:::\n:::\n\n\nIn the table above we can see that the mean scores are different and highest in the DRTA group.\n\nIf we were to run an ANOVA on the data, we might present it in the following way:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n|term      | df|    sumsq|   meansq| statistic|   p.value|\n|:---------|--:|--------:|--------:|---------:|---------:|\n|group     |  2| 108.1212| 54.06061|  5.317437| 0.0073468|\n|Residuals | 63| 640.5000| 10.16667|        NA|        NA|\n:::\n:::\n\n\nNotice that the ANOVA output tells us that the difference between groups is significant (p < 0.05) but we cannot tell yet which of the 3 groups are significantly different from each other.\n\n### Regression approach\n\nRegression asks the question the following way:\n\n> Does teaching group predict reading comprehension score?\n\nThe analysis takes the following approach:\n\n- Let's use the mean of group 1 as a reference point (i.e. the intercept).\n- What's the difference between the intercept and the mean scores of the other groups (i.e. the coefficients)?\n- Are any of the coefficients statistically significant?\n\nIf we run a regression analysis, we might present the results like this:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n|        R2|\n|---------:|\n| 0.1444271|\n:::\n\n::: {.cell-output-display}\n|term      | df|    sumsq|   meansq| statistic|   p.value|\n|:---------|--:|--------:|--------:|---------:|---------:|\n|group     |  2| 108.1212| 54.06061|  5.317437| 0.0073468|\n|Residuals | 63| 640.5000| 10.16667|        NA|        NA|\n:::\n\n::: {.cell-output-display}\n|term        | estimate| std.error| statistic|   p.value|\n|:-----------|--------:|---------:|---------:|---------:|\n|(Intercept) | 6.681818| 0.6797950|  9.829167| 0.0000000|\n|groupDRTA   | 3.090909| 0.9613753|  3.215091| 0.0020583|\n|groupStrat  | 1.090909| 0.9613753|  1.134738| 0.2607841|\n:::\n:::\n\n\n### Interpreting regression output\n\nIf we look at the coefficient (estimate) for the intercept (see regression output above), we can see that the value is the same as the mean of the Basal group in the previous section  (See table of mean and sd, above). \n\nFurthermore, if we look at the estimates of DRTA and Strat, we can see that the values are the difference between their mean score, and the score for of the intercept (BASAL) group. So we can see whether DTRA and STRAT groups are significantly different from the BASAL group.\n\nIf we wanted to compare the groups differently (e.g. using Strat as the reference point), we can use the relevel function and run the regression analysis again (See [Using categorical predictors in R])\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}