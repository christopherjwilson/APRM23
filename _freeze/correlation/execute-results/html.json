{
  "hash": "5b71f6a7e40086e53d4e931b4f78710c",
  "result": {
    "markdown": "# Correlation\n\n\n\n\n<iframe src=\"https://teesside.hosted.panopto.com/Panopto/Pages/Embed.aspx?id=c13b5ceb-47c7-4001-8a56-adaa008f19a2&autoplay=false&offerviewer=true&showtitle=true&showbrand=false&captions=false&interactivity=all\" height=\"405\" width=\"100%\" style=\"border: 1px solid #464646;\" allowfullscreen allow=\"autoplay\"></iframe>\n\n## What is Correlation?\n\n- The relationship between 2 variables\n- Question: Is treatment duration related to aggression levels?\n\n\n## How is correlation calculated?\n\n- Think of this as covariance divided by individual variance\n- If the changes are consistent with both variables, the final value will be higher\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](img/correlation.png){fig-align='center' width=100%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](img/corcalc.png){fig-align='center' width=100% height=100%}\n:::\n:::\n\n\n## Running correlation in R\n\n- Step 1: Check assumptions\n  - Data,distribution,linearity\n- Step 2: Run correlation\n- Step 3: Check R value\n- Step 4: Check significance\n\n### Check assumptions: data\n\n- Parametric tests require interval or ratio data\n- If the data are ordinal then a non-parametric correlation is used\n\n> What type of data are treatment duration and aggression level?\n\n\n### Check assumptions: distribution \n\n- Parametric tests require normally distributed data\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](correlation_files/figure-html/unnamed-chunk-3-1.png){fig-align='center' width=100%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](correlation_files/figure-html/unnamed-chunk-4-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n### Check assumptions: distribution #2\n\n- Parametric tests require normally distributed data\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nshapiro.test(regression_data$treatment_duration)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  regression_data$treatment_duration\nW = 0.94971, p-value = 0.0007939\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nshapiro.test(regression_data$aggression_level)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  regression_data$aggression_level\nW = 0.9928, p-value = 0.8756\n```\n:::\n:::\n\n - The normality assumption is less of an issue when sample size is > 30\n\n\n### Checking assumptions: linearity\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](img/curvilinear.jpg){fig-align='center' width=100%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nregression_data %>% ggplot(aes(x=treatment_duration,y=aggression_level)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](correlation_files/figure-html/unnamed-chunk-8-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n- Here we are looking to see if the relationship is linear\n\n### Run correlation\n\n- R can run correlations using the *cor.test()* command\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncor.test(regression_data$treatment_duration,regression_data$aggression_level)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's product-moment correlation\n\ndata:  regression_data$treatment_duration and regression_data$aggression_level\nt = -9.5503, df = 98, p-value = 1.146e-15\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.7838251 -0.5765006\nsample estimates:\n       cor \n-0.6942996 \n```\n:::\n:::\n\n\n### Check r Value (correlation value)\n\n- The r value tells us the strength and direction of the relationship\n- In the output it is labelled as \"cor\" (short for correlation)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncor.test(regression_data$treatment_duration,regression_data$aggression_level)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's product-moment correlation\n\ndata:  regression_data$treatment_duration and regression_data$aggression_level\nt = -9.5503, df = 98, p-value = 1.146e-15\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.7838251 -0.5765006\nsample estimates:\n       cor \n-0.6942996 \n```\n:::\n:::\n\n\n### Check the significance of the correlation\n\n- We can see that the significance by looking at the p value \n  - The significance is 1.146^-15\n  - This means: 0.0000000000000001146\n- Therefore p value < 0.05\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncor.test(regression_data$treatment_duration,regression_data$aggression_level)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's product-moment correlation\n\ndata:  regression_data$treatment_duration and regression_data$aggression_level\nt = -9.5503, df = 98, p-value = 1.146e-15\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.7838251 -0.5765006\nsample estimates:\n       cor \n-0.6942996 \n```\n:::\n:::\n\n\n\n\n# Simple Regression\n\n<iframe src=\"https://teesside.hosted.panopto.com/Panopto/Pages/Embed.aspx?id=5e657c9f-3a06-4a74-b259-adaa0090242b&autoplay=false&offerviewer=true&showtitle=true&showbrand=false&captions=false&interactivity=all\" height=\"405\" width=\"100%\" style=\"border: 1px solid #464646;\" allowfullscreen allow=\"autoplay\"></iframe>\n\n## What is regression?\n\n- Testing to see if we can make predictions based on data that are correlated\n\n> We found a strong correlation between treatment duration and agression levels. Can we use this data to predict aggression levels of other clients, based on their treatment duration?\n\n\n- When we carry out regression, we get a information about:\n  - How much variance in the **outcome** is explained by the **predictor**\n  - How confident we can be about these results generalising (i.e. **significance**)\n  - How much error we can expect from anu predictions that we make (i.e. **standard error of the estimate**)\n  - The figures we need to calculate a predicted outcome value (i.e. **coefficient values**)\n  \n## How is regression calculated?\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](img/bestfit.png){fig-align='center' width=100%}\n:::\n:::\n\n\n- When we run a regression analysis, a calculation is done to select the \"line of best fit\"\n- This is a \"prediction line\" that minimises the overall amount of error\n  - Error = difference between the data points and the line \n\n\n## The regression equation \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](img/bestfit.png){fig-align='center' width=100%}\n:::\n:::\n\n\n- Once the line of best fit is calculated, predictions are based on this line\n- To make predictions we need the **intercept** and **slope** of the line\n  - **Intercept** or **constant**= where the line crosses the y axis\n  - **Slope** or **beta** = the angle of the line\n\n\n- Predictions are made using the calculation for a line: \n **Y = bX + c**\n\n- You can think of the equation like this:\n\n **predicted outcome value = beta coefficient * value of predictor + constant **\n\n\n## Running regression in R\n\n- Step 1: Run regression\n- Step 2: Check assumptions\n  - Data\n  - Distribution\n  - Linearity\n  - Homogeneity of variance\n  - Uncorrelated predictors\n  - Indpendence of residuals\n  - No influental cases / outliers\n\n- Step 3: Check R^2 value\n- Step 4: Check model significance\n- Step 5: Check coefficient values\n\n\n## Run regression\n\n- We use the *lm()* command to run regression while saving the results \n- We then use the *summary()* function to check the results\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel1 <- lm(formula= aggression_level ~ treatment_duration ,data=regression_data)\nsummary(model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = aggression_level ~ treatment_duration, data = regression_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.4251 -1.1493 -0.0593  0.8814  3.4542 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         12.3300     0.7509   16.42  < 2e-16 ***\ntreatment_duration  -0.6933     0.0726   -9.55 1.15e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.551 on 98 degrees of freedom\nMultiple R-squared:  0.4821,\tAdjusted R-squared:  0.4768 \nF-statistic: 91.21 on 1 and 98 DF,  p-value: 1.146e-15\n```\n:::\n:::\n\n\n\n## What are residuals?\n\n- In regression, the assumptions apply to the residuals, not the data themselves\n- Residual just means the difference between the data point and the regression line\n\n\n::: {.cell layout-align=\"center\" width='100%'}\n::: {.cell-output-display}\n![](img/residuals1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n## Check assumptions: distribution\n\n- Using the *plot()* command on our regression model will give us some useful diagnostic plots\n- The second plot that it outputs shows the normality\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(model1, which=2)\n```\n\n::: {.cell-output-display}\n![](correlation_files/figure-html/unnamed-chunk-16-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n- We could also use a histogram to check the distribution\n- Notice how we can use the $ sign to get the residuals from the model\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhist(model1$residuals)\n```\n\n::: {.cell-output-display}\n![](correlation_files/figure-html/unnamed-chunk-17-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n## Check assumptions: linearity\n\n- Using the *plot()* command on our regression model will give us some useful diagnostic plots\n- The first plot that it outputs shows the residuals vs the fitted values\n- Here, we want to see them spread out, with the line being horizontal and straight \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(model1, which=1)\n```\n\n::: {.cell-output-display}\n![](correlation_files/figure-html/unnamed-chunk-18-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n- There is a slight amount of curvilinearity here but nothing to be worried about\n\n## Check assumptions: Homogeneity of Variance #1\n\n- We can use the sample plot to check Homogeneity of Variance\n- We want the variance to be constant across the data set. We do not want the variance to change at different points in the data \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(model1, which=1)\n```\n\n::: {.cell-output-display}\n![](correlation_files/figure-html/unnamed-chunk-19-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n- A violation of Homogeneity of Variance would usually look like a funnel, with the data narrowing \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](img/biasedresiduals.png){fig-align='center' width=100% height=100%}\n:::\n:::\n\n\n## Check assumptions: Influential cases \n\n\n- We need to check that there are no extreme outliers - they could throw off our predictions\n- We are looking for participants that have high rediduals + high leverage\n  - Some guidance suggests anything higher than 1 is an influential case \n  - Others suggest 4/n is the cut off point (4 divided by number of participants)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(model1, which=4)\n```\n\n::: {.cell-output-display}\n![](correlation_files/figure-html/unnamed-chunk-21-1.png){fig-align='center' width=30%}\n:::\n:::\n\n\n- We are looking for participants that have high rediduals + high leverage\n  - No cases over 1\n  - Many are over 0.04 (4/n = 0.04)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(model1, which=5)\n```\n\n::: {.cell-output-display}\n![](correlation_files/figure-html/unnamed-chunk-22-1.png){fig-align='center' width=40%}\n:::\n:::\n\n\n## Check the r squared value\n\n\n-  r^2 = the amount of variance in the **outcome** that is explained by the **predictor(s)**\n- The closer this value is to 1, the more useful our regression model is for predicting the outcome\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodelSummary <- summary(model1)\nmodelSummary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = aggression_level ~ treatment_duration, data = regression_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.4251 -1.1493 -0.0593  0.8814  3.4542 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         12.3300     0.7509   16.42  < 2e-16 ***\ntreatment_duration  -0.6933     0.0726   -9.55 1.15e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.551 on 98 degrees of freedom\nMultiple R-squared:  0.4821,\tAdjusted R-squared:  0.4768 \nF-statistic: 91.21 on 1 and 98 DF,  p-value: 1.146e-15\n```\n:::\n:::\n\n- The r^2 of 0.482052 means that 48% of the variance in **aggression level** is explained by **treatment duration**\n\n## Check model significance\n\n- The model significance is displayed at the very end of the output\n  - *p-value: 1.146e-15* \n  - As p < 0.05, the model is significant\n  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodelSummary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = aggression_level ~ treatment_duration, data = regression_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.4251 -1.1493 -0.0593  0.8814  3.4542 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         12.3300     0.7509   16.42  < 2e-16 ***\ntreatment_duration  -0.6933     0.0726   -9.55 1.15e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.551 on 98 degrees of freedom\nMultiple R-squared:  0.4821,\tAdjusted R-squared:  0.4768 \nF-statistic: 91.21 on 1 and 98 DF,  p-value: 1.146e-15\n```\n:::\n:::\n\n\n\n## Check coefficient values \n\n- The coefficient values are displayed in the coefficients table\n- If we have more than one predictor, they are all listed here\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodelSummary$coefficients\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                     Estimate Std. Error   t value     Pr(>|t|)\n(Intercept)        12.3300211 0.75087601 16.420848 6.840516e-30\ntreatment_duration -0.6933201 0.07259671 -9.550297 1.145898e-15\n```\n:::\n:::\n\n- The **beta coefficient** for treatment duration is in the *Estimate* column\n- For every unit increase in treatment duration, aggression level decreases by 0.69\n\n\n## The regression equation\n\n\n- The regression equation is:\n\nOutcome = predictor value * beta coefficient + constant\n\n- For this model, that is:\n\nAggression level = treatment duration * -0.69 + 12.33 \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodelSummary$coefficients\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                     Estimate Std. Error   t value     Pr(>|t|)\n(Intercept)        12.3300211 0.75087601 16.420848 6.840516e-30\ntreatment_duration -0.6933201 0.07259671 -9.550297 1.145898e-15\n```\n:::\n:::\n\n\n## Accounting for error in predictions\n\n- We also know that the accuracy of predictions will be within a certain margin of error\n- This is known as **standard error of the estimate** or **residual standard error**\n  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodelSummary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = aggression_level ~ treatment_duration, data = regression_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.4251 -1.1493 -0.0593  0.8814  3.4542 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         12.3300     0.7509   16.42  < 2e-16 ***\ntreatment_duration  -0.6933     0.0726   -9.55 1.15e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.551 on 98 degrees of freedom\nMultiple R-squared:  0.4821,\tAdjusted R-squared:  0.4768 \nF-statistic: 91.21 on 1 and 98 DF,  p-value: 1.146e-15\n```\n:::\n:::\n",
    "supporting": [
      "correlation_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}